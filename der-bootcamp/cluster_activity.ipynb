{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "if not os.path.isdir(\"cluster_activity_files\"):\n",
    "    os.mkdir(\"cluster_activity_files\")\n",
    "from i2x.der_hca import hca, islands as isl, PlotUtils as pltutl\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential vs. Cluster Considerations\n",
    "The purpose of this activity is to highlight the impact of considering interconnection requests sequentially versus in clusters.\n",
    "\n",
    "**Note:**<br>\n",
    "Determining the hosting capacity at multiple locations is non-trivial and in its most complete and general form becomes a highly non-linear optimization problem.\n",
    "Instead of solving this problem, we'll show how the hosting capacity changes depending on the sequencing.\n",
    "We'll then show how batching several changes and considering upgrades _afterwards_ changes the way some of the ensuing costs may be viewed.\n",
    "\n",
    "## Part 1: Location and Order Matters!\n",
    "### Setting a baseline\n",
    "To set a baseline, we'll first run the hosing capacity at each location _independently_.\n",
    "This is not an uncommon approach, but it means that each location does not take into account the resource additions anywhere else on the feeder.\n",
    "As it treats each location independently, this approach can serve as a good reference when trying to understand the impact of adding multiple resources at once.\n",
    "\n",
    "> **Note:**\n",
    "> This step can take a few minutes. If your computer is acting up or you simply don't feel like waiting, a saved version of the result is under [saved_resources/independet_hca.pkl](./saved_resources/independent_hca.pkl). Simply copy that file into the `cluster_activity_files` folder and everything else should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to actually perform the independent HCA\n",
    "logger_header = f\"\\n************* Order Independent HCA ******************\\n\"\n",
    "feeder = hca.HCA(\"./configs/cluster_activity.json\", logger_heading=logger_header)\n",
    "feeder.runbase()\n",
    "\n",
    "## For each bus, calculate HC but don't add anything to feeder.\n",
    "for b in feeder.graph_dirs[\"bus3phase\"]:\n",
    "    feeder.hca_round(\"pv\", bus=b, recalculate=True)\n",
    "feeder.save(\"./cluster_activity_files/independent_hca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to load the saved result\n",
    "logger_header = f\"\\n************* Loading Independent HCA ******************\\n\"\n",
    "feeder = hca.HCA(\"./cluster_activity_files/independent_hca.pkl\", reload=True, reload_filemode=\"a\",\n",
    "                 logger_heading=logger_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the hosting capacity on the feeder (hover over the individual buses to see the values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot HCA\n",
    "pltutl.hc_plot(feeder, \"./cluster_activity_files/independent_hca\", auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query the hosting capacity at a particular bus (or at all buses).\n",
    "\n",
    "> **Note:**\n",
    "> To query all buses simply replace the `bus` argument with `None`\n",
    "> The output just becomes rather large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = \"bus_1112\"\n",
    "if bus is None:\n",
    "    hc = feeder.get_data(\"hc\", \"pv\")\n",
    "    display(hc)\n",
    "else:\n",
    "    hc, cnt = feeder.get_data(\"hc\", \"pv\", bus=bus, cnt=0)\n",
    "    print(f\"Hosting Capacity at bus {bus} is {round(hc['kw'],2)} kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic resource addition\n",
    "In the first experiment, we continually add resources, sampling both location and capacity randomly.\n",
    "We stop whenever a resource encounters a limitation and is therefore not able to interconnect its full desired capacity (without some upgrade needs).\n",
    "\n",
    "First, we will consider the addition of several resources and simply shuffle the order in which they are added to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run the experiment 3 times\n",
    "rng = np.random.default_rng(0) # random number generator with seed specified for reproducibility\n",
    "for i in range(3):\n",
    "\n",
    "    ### reload the feeder with the independent HCA data\n",
    "    logger_header = f\"\\n************* Re-Loading Independent HCA, Order Experiment Round {i} ******************\\n\"\n",
    "    feeder = hca.HCA(\"./cluster_activity_files/independent_hca.pkl\", reload=True, reload_filemode=\"a\",\n",
    "                    logger_heading=logger_header)\n",
    "    if i > 0:\n",
    "        ### permuting the order of addition\n",
    "        # using feeder random state for reproducibility\n",
    "        resource_order = rng.permutation(len(added_resources))\n",
    "        while resource_order[-1] == len(resource_order) - 1:\n",
    "            # make sure we don't put the original resource causing violation last\n",
    "            resource_order = rng.permutation(len(added_resources))\n",
    "        j = 0\n",
    "    ### add resources until one is limited (hc = 0)\n",
    "    while True:\n",
    "        if i == 0:\n",
    "            ## on first round sampling is done randomly\n",
    "            feeder.hca_round(\"pv\")\n",
    "        else:\n",
    "            ## on subsequent rounds sampling is based on a reordering of the first round\n",
    "            bus, Sij = added_resources[resource_order[j]]\n",
    "            j += 1\n",
    "            feeder.hca_round(\"pv\", bus=bus, Sij=Sij)\n",
    "        ## get the hosting capacity for the last bus considered, if zero, then likely capacity was limited\n",
    "        hc, cnt = feeder.get_hc(\"pv\", feeder.visited_buses[-1], feeder.cnt)\n",
    "        if hc[\"kw\"] == 0:\n",
    "            ## there are violations with initial desired capacity\n",
    "            # reload last step\n",
    "            feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\", reload=True, \n",
    "                                reload_filemode=\"a\", logger_heading=\"\\n*****Re-loading pre capacity limitation******\\n\")\n",
    "            if i == 0:\n",
    "                feeder.hca_round(\"pv\", allow_violations=True)\n",
    "            else:\n",
    "                feeder.hca_round(\"pv\", bus=bus, Sij=Sij, allow_violations=True) #re-run allowing for violations\n",
    "            feeder.save(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\") #save again for later intialization\n",
    "            break\n",
    "        else:\n",
    "            ## save for later re-wind\n",
    "            feeder.save(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\")\n",
    "\n",
    "    if i == 0:\n",
    "        ## on the first iteration we save the resources added so we can reapply the same ones\n",
    "        added_resources = []\n",
    "        for j in range(1, feeder.cnt+1):\n",
    "            bus = feeder.visited_buses[j-1]\n",
    "            sij, _ = feeder.get_data(\"Sij\", \"pv\", bus=bus, cnt=j)\n",
    "            added_resources.append((bus, sij))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just look at the results.\n",
    "We can look at:\n",
    "* How much capacity is integrated onto the feeder at the time of the violation?\n",
    "* Where is the the resource triggering the violation?\n",
    "* What sort of violation is triggered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\", \n",
    "                 reload=True, reload_filemode=\"a\", \n",
    "                 logger_heading=f\"\\n*****Re-loading post-violation stochastic round {i}******\\n\")\n",
    "feeder.metrics.load_res(feeder.lastres)\n",
    "feeder.metrics.calc_metrics()\n",
    "installed_kw = feeder.data[\"Stotal\"][feeder.cnt].loc[\"pv\", \"kw\"]\n",
    "feeder.logger.info(f'Installed Capacity:\\n {installed_kw:0.2f} kW')\n",
    "hca.print_config(feeder.metrics.violation, printf=feeder.logger.info, title=\"Violations\")\n",
    "pltutl.hc_plot(feeder, f\"./cluster_activity_files/cluster_activity_stoch_i{i}_step1\",\n",
    "            highlight_nodes={feeder.visited_buses[-1]: f\"{','.join(feeder.metrics.last_violation_list)}\"},\n",
    "            title=f\"Stochastic Round {i}: Total Installed Capacity {installed_kw:0.2f} kW\",\n",
    "            auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to independent hosting capacity\n",
    "We can compare the initial, independent hosting capacity, to the one calculated with the resources added.\n",
    "Since the last resource added in each round causes a violation, we do this by removing the last resource and re-calculating the hosting capacity in this state.\n",
    "Rather than perform the recalculation for _all_ buses in the feeder, we focus just on the ones where resources were added in any of the three experiments.\n",
    "Comparing these results over all 4 cases (independent calculation + 3 experiments) illustrates directly how the hosting capacity is affected by sequencing.\n",
    "\n",
    ">**Note:** In this analysis the hosting capacity for resources that _were_ added to the circuit is given for the point in time where they were added.\n",
    ">Resources that were added in the first run but not the others are recalculated on the last round with no iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "for i in range(3):\n",
    "    ### Load run\n",
    "    feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\",\n",
    "                    logger_heading=f\"\\n***** Difference to Independent Method {i} *****\\n\")\n",
    "    feeder.metrics.load_res(feeder.lastres)\n",
    "    feeder.metrics.calc_metrics()\n",
    "    if i == 0:\n",
    "        buslist = list(reversed(feeder.visited_buses))\n",
    "    else:\n",
    "        buslist = [feeder.visited_buses[-1]] + [b for b in buslist if b != feeder.visited_buses[-1]]\n",
    "    ### loop over buses except for the last where the HC is 0 since we have a violation\n",
    "    for j, b in enumerate(buslist):\n",
    "        if j == 0:\n",
    "            ### for the last bus we'll undo the addition and recalculate the HCA since\n",
    "            ### What is on the feeder right now causes a violation\n",
    "            feeder.undo_hca_round(\"pv\", b, feeder.cnt)\n",
    "            feeder.hca_round(\"pv\", bus=b, recalculate=True)\n",
    "        elif b not in feeder.visited_buses:\n",
    "            ### This bus wasn't reached in this experiment, recalculate its hosting capacity BEFORE \n",
    "            ### The violation triggering addition is made\n",
    "            feeder.hca_round(\"pv\", bus=b, recalculate=True)\n",
    "        if b not in out:\n",
    "            hc, cnt = feeder.get_hc(\"pv\", b, cnt=0) # get the hosting capacity\n",
    "            \n",
    "            out[b] = {\"independent\": hc[\"kw\"]}\n",
    "        \n",
    "        hc, cnt = feeder.get_hc(\"pv\", b) # get the hosting capacity\n",
    "        if b not in feeder.visited_buses:\n",
    "            # undo_hca_round removes from visited buses\n",
    "            out[b][f\"Sequence {i}\"] = hc[\"kw\"]\n",
    "        else:\n",
    "            sij, cnt = feeder.get_data(\"Sij\", \"pv\", b, cnt) # get the added capacity\n",
    "            out[b][f\"Sequence {i}\"] = hc[\"kw\"] + sij[\"kw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display and Plot\n",
    "df = pd.DataFrame.from_dict(out, orient=\"index\").sort_values(by=\"independent\", axis=0)\n",
    "display(df)\n",
    "df.plot.bar(barmode='group', backend='plotly',\n",
    "            labels={\"value\": \"Hosting Capacity [kW]\", \"index\": \"bus\"},\n",
    "            title=\"Difference In Hosting Capacity by Sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "The independent HCA presents an _upper bound_ for the hosting capacity.\n",
    "As more resources are added, depending on their location and size w.r.t. any given bus, the resulting hosting capacity may be impacted more or less.\n",
    "\n",
    "We simulated each of the three experiments as a sequence of additions, however, we can also think about the final state as a _single cluster_ of resources, under study that result in a violation.\n",
    "In the [next section](#part-2-upgrades) we consider the upgrades necessary for each of the of experiments and then turn our attention to the implication of the sequential vs. cluster framing in terms of costs in [Part 3](#part-3-cost-sharing).\n",
    "\n",
    "## Part 2: Upgrades\n",
    "We've already seen in the [voltage difference activity](./vdiff_activity.ipynb) that for the $\\Delta V$ violations, upgrading the conductors, as well as activating advanced inverter functions can help to alleviate the violations by forming a stronger connection to the feeder source.\n",
    "\n",
    "To keep from conflating too many factors, we'll focus on the conductor upgrades here, and leave out the advanced inverter functions.\n",
    "The reason fro this is that the inverter functions would impact the underlying independent hosting capacity results as well.\n",
    "\n",
    "For each of our three experiments, we'll perform the upgrades, moving towards the feeder head, until no more violations are encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "####### these are some functions to get the path and perform the upgrades\n",
    "#########################################################################\n",
    "def get_upgrade_path(feeder:hca.HCA):\n",
    "    \"\"\"get the path from the furthest location from the source bus, where\n",
    "    a voltage difference problem occurs, to the source bus\n",
    "    \"\"\"\n",
    "    ### collect locations where voltage difference is violated\n",
    "    vdiff_buses = list(feeder.metrics.get_vdiff_locations()[\"v\"].keys())\n",
    "    sources = []\n",
    "    upgrade_paths = []\n",
    "    path_lengths = []\n",
    "    ### for each location with a violation, find the path to the source bus\n",
    "    for b in vdiff_buses:\n",
    "        nearest_source, path2source = isl.get_nearest_source(feeder.G.to_undirected(), b)\n",
    "        sources.append(nearest_source)\n",
    "        upgrade_paths.append(path2source)\n",
    "        path_lengths.append(len(path2source))\n",
    "    ### select the maximum distance to the source bus.\n",
    "    idx = np.argmax(path_lengths)\n",
    "    return upgrade_paths[idx]\n",
    "\n",
    "def upgrade_until_no_violation(feeder:hca.HCA, upgrade_path:list, multiupgrade=True):\n",
    "    \"\"\"Iterate over the path to the source and upgrade the conductor \n",
    "    until no violations\n",
    "    \"\"\"\n",
    "    for u,v in zip(upgrade_path[1:], upgrade_path[:-1]):\n",
    "        eclass = feeder.G.edges[u,v][\"eclass\"]\n",
    "        ename = feeder.G.edges[u,v][\"ename\"]\n",
    "        if eclass.lower() == \"line\":\n",
    "            if not multiupgrade:\n",
    "                if feeder.get_data(\"upgrades\", \"line\", ename)[0] is not None:\n",
    "                    # segment already updated\n",
    "                    continue\n",
    "            feeder.upgrade_line(ename)\n",
    "        \n",
    "        ## run dss\n",
    "        feeder.reset_dss(clear_changes=False)\n",
    "        feeder.rundss()\n",
    "        if not feeder.lastres[\"converged\"]:\n",
    "            raise ValueError(\"Open DSS did not converge\")\n",
    "        \n",
    "        feeder.metrics.load_res(feeder.lastres)\n",
    "        feeder.metrics.calc_metrics()\n",
    "        \n",
    "        ## check if there are any violations\n",
    "        if feeder.metrics.violation_count == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ### Load run\n",
    "    feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\",\n",
    "                    logger_heading=f\"\\n***** Performing Upgrades for Run {i} *****\\n\")\n",
    "    feeder.metrics.load_res(feeder.lastres)\n",
    "    feeder.metrics.calc_metrics()\n",
    "\n",
    "    ### get the path to upgrade\n",
    "    upgrade_path = get_upgrade_path(feeder)\n",
    "    feeder.logger.info(f\"Furthest violation from substation on bus {upgrade_path[0]}\")\n",
    "\n",
    "    ### Perform the upgrades\n",
    "    upgrade_until_no_violation(feeder, upgrade_path)\n",
    "    feeder.logger.info(f\"Estimated upgrade cost:\")\n",
    "    new_upgrades = feeder.get_data('upgrades', 'line', cnt=feeder.cnt)\n",
    "    feeder.logger.info(f\"\\tLines: ${new_upgrades['cost'].sum():0.2f} | {new_upgrades.apply(lambda x: x.length*hca.conductor_cost.units2ft(x.length_unit), axis=1).sum():0.2f} ft\")\n",
    "    \n",
    "    ### Update hosting capacity at all buses under consideration:\n",
    "    if i == 0:\n",
    "        buslist = feeder.visited_buses.copy()\n",
    "    for b in buslist:\n",
    "        feeder.hca_round(\"pv\", bus=b, recalculate=True)\n",
    "    pltutl.upgrade_plot(feeder, f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade1\", include_plotlyjs='cdn', auto_open=True)\n",
    "    feeder.save(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we gather some summary statistics for each of the experiments and look at:\n",
    "* _Total installed capacity_: total added capacity to the feeder;\n",
    "* _Triggering capacity_: the capacity of the last unit that triggers the updates;\n",
    "* _Total upgrade costs_: total costs needed to remove violations under the presence of the _Total installed capacity_;\n",
    "\n",
    "and consider how these variables relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "for i in range(3):\n",
    "    ### Load run\n",
    "\n",
    "    feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade1.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\")\n",
    "    feeder.metrics.load_res(feeder.lastres)\n",
    "    feeder.metrics.calc_metrics()\n",
    "\n",
    "    out[f\"sequence {i}\"] = {}\n",
    "    ### The upgrades\n",
    "    out[f\"sequence {i}\"].update(\n",
    "        feeder.get_data(\"upgrades\", \"line\").agg({\n",
    "                                         \"cost\": \"sum\", \n",
    "                                         \"length\": \"sum\",\n",
    "                                         \"length_unit\": \"unique\",\n",
    "                                         \"cnt\": \"count\"}).to_dict()\n",
    "    )\n",
    "    ### Total installed capacity\n",
    "    out[f\"sequence {i}\"][\"total kw\"] = feeder.data[\"Stotal\"][feeder.cnt].loc[\"pv\", \"kw\"]\n",
    "\n",
    "    ### triggering unit\n",
    "    bus = feeder.visited_buses[-1]\n",
    "    bus_kw= feeder.get_data(\"Sij\", \"pv\", bus, feeder.cnt)[0][\"kw\"]\n",
    "    out[f\"sequence {i}\"].update({\"trigger bus\": bus, \"trigger kw\": bus_kw})\n",
    "\n",
    "df = pd.DataFrame(out)\n",
    "print(\"Tabular Comparison\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Installed Capacity vs. Cost\n",
    "The way the experiment was set up, the first run will always have the most installed capacity.\n",
    "This is because the total capacity was limited to the set of resources that was integrated in the first run.\n",
    "The motivation for this setup is that each run can represent different realizations of resources entering the queue, while at the same time the full set can be treated separately as a single cluster.\n",
    "Nonetheless, it is interesting to see how the total installed capacity relates to the total upgrade costs, as plotted in the figures below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels= [f'{df.T[\"total kw\"][idx]:0.1f} kW (total)<br>${df.T[\"cost\"][idx]:0.2f}' for idx in df.T.index]\n",
    "fig = df.loc[[\"cost\", \"total kw\"]].T.assign(cost_per_kw=lambda x: x[\"cost\"]/x[\"total kw\"]).plot.bar(backend='plotly', \n",
    "            x=df.T.index, y='cost_per_kw',\n",
    "            color=df.T.index,\n",
    "            text = txt_labels ,\n",
    "            labels={\"cost_per_kw\": \"$/kW\", \"x\": \"experiment\", \"color\": \"experiment\"},\n",
    "            title=\"Cost per Installed kW (total)\")\n",
    "fig.update_layout(width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggering Capacity vs. Cost\n",
    "In a standard sequential queue process the triggering unit is generally responsible for upgrade costs. \n",
    "It is therefore interesting to consider what those costs are w.r.t the capacity of the triggering unit.\n",
    "\n",
    "Recall that in both the first and last experiment, the unit on `bus_1113` triggers the upgrades, while in the second experiment it is the unit on `bus_1112`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_labels= [f'{df.T[\"trigger kw\"][idx]} kW (trigger)<br>${df.T[\"cost\"][idx]}' for idx in df.T.index]\n",
    "fig = df.loc[[\"cost\", \"trigger kw\"]].T.assign(cost_per_kw=lambda x: x[\"cost\"]/x[\"trigger kw\"]).plot.bar(backend='plotly', \n",
    "            x=df.T.index, y='cost_per_kw',\n",
    "            color=df.T.index,\n",
    "            text = txt_labels,\n",
    "            labels={\"cost_per_kw\": \"$/kW\", \"x\": \"experiment\", \"color\": \"experiment\"},\n",
    "            title=\"Cost per Installed kW (triggering)\")\n",
    "fig.update_layout(width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of cost per capacity\n",
    "Finally, we compare the $/kW for the total capacity and triggering capacity cases.\n",
    "As expected, when associated with the triggering capacity, the costs are several times greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df.loc[[\"cost\", \"total kw\", \"trigger kw\"]].transpose().assign(\n",
    "    cost_per_kw_tr=lambda x: x[\"cost\"]/x[\"trigger kw\"],\n",
    "    cost_per_kw_to=lambda x: x[\"cost\"]/x[\"total kw\"]).loc[:, [\"cost_per_kw_tr\", \"cost_per_kw_to\"]]\n",
    "\n",
    "txt = [f'{df_comp[\"cost_per_kw_tr\"][idx]/df_comp[\"cost_per_kw_to\"][idx]:0.1f}x' for idx in df_comp.index]\n",
    "fig = pd.DataFrame(df_comp.to_dict()).plot.bar(backend='plotly', barmode=\"group\",\n",
    "                        labels={\"value\": \"$/kW\", \"index\": \"experiment\"},\n",
    "                        title=\"Comparison of $/kW for total and triggering capacity\")\n",
    "fig.data[0].text = txt\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing the queue\n",
    "The previous comparisons are not exactly \"fair\", in that they are essentially comparing the system between different stages of evolution.\n",
    "They help illustrate that depending on which resources are integrated, where they are integrated, and when they are integrated, upgrades occur at different times and magnitudes, triggered by different units.\n",
    "\n",
    "When considering sequential versus cluster processes, what we're _really_ trying to focus on is the impact of _time_.\n",
    "To better isolate the time dimension from our experiments, for sequences 2 and 3, we continue to add resources, targeting the same capacity as the first experiment and add upgrades as they occur.\n",
    "The result are three experiments with identical installed capacity.\n",
    "Because of the simplified upgrade methodology used, the results also have exactly the same set of final upgrades.\n",
    "Therefore, the only difference is _when_ the upgrades take place, and thus, which units are responsible for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "### Upgrade Runs 2 and 3 to same capacity as run 1\n",
    "#####################################################\n",
    "### get the resource list\n",
    "feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i0_upgrade1.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\")\n",
    "resources = feeder.get_data(\"Sij\", \"pv\")\n",
    "\n",
    "# random number generator with seed specified for reproducibility\n",
    "# Note: because we are seeding and using the random number generator in the same order as during the generation\n",
    "# of these runs, the resource orders created here will match those from before.\n",
    "rng = np.random.default_rng(0) \n",
    "\n",
    "for i in range(1,3):\n",
    "    resource_order = rng.permutation(resources.shape[0])\n",
    "    while resource_order[-1] == len(resource_order) - 1:\n",
    "        # make sure we don't put the original resource causing violation last\n",
    "        resource_order = rng.permutation(len(resource_order))\n",
    "    ### Load run\n",
    "    logger_header = f\"\\n************* Loading upgraded run Sequence {i}******************\\n\"\n",
    "    feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade1.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\",\n",
    "                    logger_heading=logger_header)\n",
    "    feeder.metrics.load_res(feeder.lastres)\n",
    "    feeder.metrics.calc_metrics()\n",
    "    upgrade_round = 2\n",
    "    while feeder.cnt < resources.shape[0]:\n",
    "        \n",
    "        ## get bus and capacity\n",
    "        bus = resources.iloc[resource_order].iloc[feeder.cnt].name\n",
    "        Sij = resources.iloc[resource_order].loc[bus, [\"kw\", \"kva\"]].to_dict()\n",
    "        \n",
    "        ## add bus and check for violations\n",
    "        feeder.hca_round(\"pv\", bus=bus, Sij=Sij, allow_violations=True)\n",
    "\n",
    "        if feeder.metrics.violation_count > 0:\n",
    "            # violations occured\n",
    "            if not \"voltage_vdiff\" in feeder.metrics.last_violation_list:\n",
    "                feeder.logger.info(f\"Expected voltage difference violation but encountered {feeder.metrics.last_violation_list}.\")\n",
    "                feeder.logger.info(f\"saving to ./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade2.pkl and exiting.\")\n",
    "                feeder.save(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade{upgrade_round}.pkl\")\n",
    "                break\n",
    "            \n",
    "            feeder.logger.info(f\"\\n******* Starting upgrade round {upgrade_round} *********\\n\")\n",
    "            ## get upgrade path\n",
    "            upgrade_path = get_upgrade_path(feeder)\n",
    "            feeder.logger.info(f\"Furthest violation from substation on bus {upgrade_path[0]}\")\n",
    "            \n",
    "            ### Perform the upgrades\n",
    "            ### assumption: we're not going to upgrade segments twice\n",
    "            upgrade_until_no_violation(feeder, upgrade_path, multiupgrade=False)\n",
    "            feeder.logger.info(f\"Estimated upgrade cost (upgrade round {upgrade_round}, hca round {feeder.cnt}):\")\n",
    "            new_upgrades = feeder.get_data('upgrades', 'line', cnt=feeder.cnt)\n",
    "            feeder.logger.info(f\"\\tLines: ${new_upgrades['cost'].sum():0.2f} | {new_upgrades.apply(lambda x: x.length*hca.conductor_cost.units2ft(x.length_unit), axis=1).sum():0.2f} ft\")\n",
    "            \n",
    "            ### save\n",
    "            feeder.save(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade{upgrade_round}.pkl\")\n",
    "            upgrade_round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(3):\n",
    "    j = 1\n",
    "    while True:\n",
    "        try:\n",
    "            feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade{j}.pkl\", \n",
    "                        reload=True, reload_filemode=\"a\")\n",
    "            j += 1\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "    if i == 0:\n",
    "        colors = pltutl.ColorList()\n",
    "        cmap = {b: colors.colors[i] for i,b in enumerate(feeder.visited_buses)}\n",
    "    df[i] = feeder.get_data(\"Sij\", \"pv\").reset_index(names=\"bus\").merge(\n",
    "        feeder.get_data(\"upgrades\", \"line\"), \n",
    "            how=\"inner\", on=\"cnt\").groupby(\"bus\").agg(\n",
    "                {\"kw\": \"first\", \"cost\": \"sum\"}).assign(**{\"$/kw\": lambda x: x.cost/x.kw})\n",
    "\n",
    "fig = pltutl.make_subplots(2,3, shared_xaxes=True, shared_yaxes=True,\n",
    "                            subplot_titles=(\"sequence 1\", \"sequence 2\", \"sequence 3\"))\n",
    "for i in range(3):\n",
    "    fig.add_trace(pltutl.go.Bar(x=df[i].index, y=df[i][\"cost\"],\n",
    "                                name=\"cost[$]\", customdata=df[i][\"kw\"].values,\n",
    "                                marker_color=[cmap[idx] for idx in df[i].index],\n",
    "                                hovertemplate=\"%{x}<br>$%{y:0.2f}<br>%{customdata} kW\"), row=1,col=i+1)\n",
    "    fig.add_trace(pltutl.go.Bar(x=df[i].index, y=df[i][\"$/kw\"], \n",
    "                                name=\"$/kW\", customdata=df[i][\"kw\"].values,\n",
    "                                marker_color=[cmap[idx] for idx in df[i].index],\n",
    "                                hovertemplate=\"%{x}<br>$%{y:0.2f}/kW<br>%{customdata} kW\"), row=2,col=i+1)\n",
    "fig.update_layout(title=\"Upgrade Costs\", showlegend=False, width=800, height=600)\n",
    "fig.update_yaxes(title_text=\"cost [$]\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"$/kW\", row=2, col=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure clearly illustrates the vast differences between different queue realizations.\n",
    "Bus 1113 is responsible for between $0 and 3 million dollars worth of upgrades for the installation of 567 kW unit.\n",
    "\n",
    "This leads to the final section of this exercise, where we consider how hosting capacity analysis might be use to allocate costs between multiple projects within a cluster.\n",
    "\n",
    "## Part 3: Cost Sharing\n",
    "As seen in the previous section, the necessary upgrades are attributed to different resources, depending on sequencing.\n",
    "If we consider all resources as part of a single cluster, we can use the hosting capacity analysis to understand the benefit that the upgrades bring to each location.\n",
    "The objective of this section is to come up with a quantifiable methodology for allocating the costs of necessary upgrades, while taking out the strong variability due to queue sequence.\n",
    "\n",
    "There are different ways to go about this. but we stick here to the _independent_ hosting capacity, because the the other calculation methods combine the impact of the other resources inherently.\n",
    "As a first step, we would like to isolate the impact/benefit of a set of upgrades on an individual location.\n",
    "To achieve this, we perform the updates, and then recalculate the independent hosting capacities.\n",
    "\n",
    "Cost sharing is determined in the following way:\n",
    "1. We calculate a $\\Delta HC_i$ for each location, $i$.\n",
    "2. From $\\Delta HC_i$ we get the percent change in HC as $\\Delta HC_i/HC_i^0$, where $HC_i^0$ is the pre-upgrade hosting capacity at location $i$.\n",
    "3. Next, the installed capacity is weighted by the hosting capacity percent change, to give a weighted-installed-capacity: $w_i[kW] = P_i \\cdot \\Delta HC_i/HC_i^0$\n",
    "4. Finally, the cost share is allocated based on the weighted-installed-capacity: $c_i[\\$] = c_{total}[\\$] * w_i/\\sum_i w_i$  \n",
    "\n",
    "Using this approach, the benefit of the upgrades to each project are weighted, as well as the actual capacity to be installed.\n",
    "\n",
    "The cost sharing calculation is performed for the first sequence only, since, [as noted before](#continuing-the-queue), the final upgrades and total cost are equal for the three sequences once all units/upgrades have been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Independent HC Change ###########\n",
    "### Load feeder with upgrades\n",
    "feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i0_upgrade1.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\")\n",
    "logger_header = f\"\\n************* Loading Independent HCA: Cost Share Analysis Sequence 0******************\\n\"\n",
    "feeder_ind = hca.HCA(\"./cluster_activity_files/independent_hca.pkl\", reload=True, reload_filemode=\"a\",\n",
    "                logger_heading=logger_header)\n",
    "\n",
    "### copy upgrades from snapshot with upgrades to the independent HCA snapshot\n",
    "feeder_ind.copy_upgrades(feeder)\n",
    "\n",
    "# increment HCA round to not overwrite data\n",
    "feeder_ind.cnt += 1 \n",
    "\n",
    "### Iterate over the added resource buses and recalculate the HCA\n",
    "for b in feeder.visited_buses:\n",
    "    ## initialize HC search with last hc value\n",
    "    hc0 = feeder_ind.get_hc(\"pv\", b, cnt=0)[0]\n",
    "    feeder_ind.hca_round(\"pv\", bus=b, Sij=hc0, recalculate=True)\n",
    "\n",
    "### now actually add the resources so they are available in this instance\n",
    "for b in feeder.visited_buses:\n",
    "    Sij = feeder.get_data(\"Sij\", \"pv\", bus=b)[0]\n",
    "    # add the resources (no need to iterate and find the HC)\n",
    "    feeder_ind.hca_round(\"pv\", bus=b, Sij=Sij, hciter=False, allow_violations=True)\n",
    "    feeder_ind.cnt -=1 # keep all resources at last iteration\n",
    "feeder_ind.cnt += 1\n",
    "feeder_ind.save(\"./cluster_activity_files/cluster_activity_cost_share.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Gather the results and calculate the cost share\n",
    "feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_cost_share.pkl\", \n",
    "                    reload=True, reload_filemode=\"a\")\n",
    "\n",
    "out = {\"bus\":[], \"hc_pre\":[], \"hc_post\":[], \"hc_delta\": []}\n",
    "for b in feeder.visited_buses:\n",
    "    hc0 = feeder_ind.get_hc(\"pv\", b, cnt=0)[0] #round 0 is the initial\n",
    "    hc1 = feeder.get_hc(\"pv\", b, cnt=1)[0]     #round 1 is after the updates (round 2 has resources added)\n",
    "    out[\"bus\"].append(b)\n",
    "    out[\"hc_pre\"].append(hc0[\"kw\"])\n",
    "    out[\"hc_post\"].append(hc1[\"kw\"])\n",
    "    out[\"hc_delta\"].append(hc1[\"kw\"] - hc0[\"kw\"])\n",
    "\n",
    "### Cost Share\n",
    "# get the percent HC change\n",
    "# weight the installed capacity by the percent HC change\n",
    "# cost share is weighted installed capacity / sum weighted installed capacity\n",
    "# cost is total cost * cost share.\n",
    "out = pd.DataFrame(out).set_index(\"bus\").join(feeder.get_data(\"Sij\", \"pv\")).assign(\n",
    "    per_delta = lambda x: 100*x[\"hc_delta\"]/x[\"hc_pre\"],\n",
    "    w_cap=lambda x: x.per_delta*x.kw/100,\n",
    "    cost_share=lambda x: x.w_cap/sum(x.w_cap),\n",
    "    cost=lambda x: x.cost_share * feeder.get_data(\"upgrades\", \"line\")[\"cost\"].sum(),\n",
    "    **{\"$/kw\": lambda x: x.cost/x.kw}\n",
    ")\n",
    "\n",
    "#### Plot\n",
    "colors = pltutl.ColorList()\n",
    "cmap = {b: colors.colors[i] for i,b in enumerate(feeder.visited_buses)}\n",
    "fig = pltutl.make_subplots(2,1, shared_xaxes=True, shared_yaxes=True)\n",
    "\n",
    "fig.add_trace(pltutl.go.Bar(x=out.index, y=out[\"cost\"],\n",
    "                            name=\"cost[$]\", customdata=out[\"kw\"].values,\n",
    "                            marker_color=[cmap[idx] for idx in out.index],\n",
    "                            hovertemplate=\"%{x}<br>$%{y:0.2f}<br>%{customdata} kW\"), row=1,col=1)\n",
    "fig.add_trace(pltutl.go.Bar(x=out.index, y=out[\"$/kw\"], \n",
    "                            name=\"$/kW\", customdata=out[\"kw\"].values,\n",
    "                            marker_color=[cmap[idx] for idx in out.index],\n",
    "                            hovertemplate=\"%{x}<br>$%{y:0.2f}/kW<br>%{customdata} kW\"), row=2,col=1)\n",
    "fig.update_layout(title=\"Upgrade costs with HCA based cost sharing\", showlegend=False, width=800, height=600)\n",
    "fig.update_yaxes(title_text=\"cost [$]\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"$/kW\", row=2, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to sequential process\n",
    "The costs determined based on the $\\Delta HC$ concept are now compared to the sequence based costs from [the previous section](#continuing-the-queue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(3):\n",
    "    j = 1\n",
    "    while True:\n",
    "        try:\n",
    "            feeder = hca.HCA(f\"./cluster_activity_files/cluster_activity_stoch_i{i}_upgrade{j}.pkl\", \n",
    "                        reload=True, reload_filemode=\"a\")\n",
    "            j += 1\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "    \n",
    "    df[i] = feeder.get_data(\"Sij\", \"pv\").reset_index(names=\"bus\").merge(\n",
    "        feeder.get_data(\"upgrades\", \"line\"), \n",
    "            how=\"inner\", on=\"cnt\").groupby(\"bus\").agg(\n",
    "                {\"kw\": \"first\", \"cost\": \"sum\"}).assign(**{\"$/kw\": lambda x: x.cost/x.kw})\n",
    "\n",
    "df[3] = out\n",
    "### plot\n",
    "fig = pltutl.make_subplots(2,4, shared_xaxes=True, shared_yaxes=True,\n",
    "                            subplot_titles=(\"sequence 1\", \"sequence 2\", \"sequence 3\", \"HCA Cost Sharing\"))\n",
    "for i in range(4):\n",
    "    fig.add_trace(pltutl.go.Bar(x=df[i].index, y=df[i][\"cost\"],\n",
    "                                name=\"cost[$]\", customdata=df[i][\"kw\"].values,\n",
    "                                marker_color=[cmap[idx] for idx in df[i].index],\n",
    "                                hovertemplate=\"%{x}<br>$%{y:0.2f}<br>%{customdata} kW\"), row=1,col=i+1)\n",
    "    fig.add_trace(pltutl.go.Bar(x=df[i].index, y=df[i][\"$/kw\"], \n",
    "                                name=\"$/kW\", customdata=df[i][\"kw\"].values,\n",
    "                                marker_color=[cmap[idx] for idx in df[i].index],\n",
    "                                hovertemplate=\"%{x}<br>$%{y:0.2f}/kW<br>%{customdata} kW\"), row=2,col=i+1)\n",
    "fig.update_layout(title=\"Upgrade Costs\", showlegend=False, width=800, height=600)\n",
    "fig.update_yaxes(title_text=\"cost [$]\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"$/kW\", row=2, col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.concat(\n",
    "    [df[i][\"cost\"] for i in range(4)], \n",
    "    keys=[\"sequence 1\", \"sequence 2\", \"sequence 3\", \"HCA Cost Sharing\"], axis=1).fillna(0).T.plot.bar(\n",
    "        backend='plotly',\n",
    "        labels={\"value\": \"cost [$]\", \"index\": \"experiment\"},\n",
    "        title=\"Cost Sharing vs. Sequential Processing\"\n",
    "    )\n",
    "for d in fig.data:\n",
    "    d.marker.color = cmap[d.name]\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = pd.concat([out[i][\"cost\"] for i in range(3)], keys=[f\"sequence {i}\" for i in range(3)], axis=1).fillna(0).plot.bar(\n",
    "#     barmode='group', backend='plotly',\n",
    "#     labels={\"value\": \"cost [$]\", \"variable\": \"experiment\"},\n",
    "#     title=\"Delta HC based cost share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_labels = [f'{out[i][\"kw\"].sum()} kW<br>(total)' for i in range(3)]\n",
    "# fig = pd.concat([out[i][\"cost\"] for i in range(3)], keys=[f\"sequence {i}\" for i in range(3)], axis=1).fillna(0).T.plot.bar(\n",
    "#     backend='plotly',\n",
    "#     labels={\"value\": \"cost [$]\", \"index\": \"experiment\"},\n",
    "#     title=\"Delta HC based cost share: distribution within clusters\")\n",
    "# fig.data[-1].text = txt_labels\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scatter figure\n",
    "# fig = df.loc[[\"cost\", \"total kw\"]].transpose().plot.scatter(backend='plotly',\n",
    "#     x=\"total kw\", y=\"cost\", color=df.T.index,\n",
    "#     labels={\"cost\" : \"cost [$]\", \n",
    "#             \"total kw\": \"total installed capacity [kW]\",\n",
    "#             \"index\": \"experiment\"},\n",
    "#     title=\"Total Installed Capacity vs. Cost\")\n",
    "# fig.update_traces(marker_size=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
